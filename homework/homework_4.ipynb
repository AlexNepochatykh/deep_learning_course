{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Постройте модель для классификации FashionMNIST. Попробуйте получить качество на тестовой выборке не ниже 89,5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('../data/', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('../data/', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x192d45fdcf8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[19][0].numpy().reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    # model testing\n",
    "    X = train_dataset[0][0]\n",
    "    X = X.reshape(1, 1, 28, 28)\n",
    "    print(X.shape)\n",
    "    for l in model:\n",
    "        X = l(X)\n",
    "        print(\"Layer {}. X shape: {}\".format(l, X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(num_epochs, model):\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "\n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "\n",
    "        model.eval()\n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "\n",
    "        print(\"ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_probaility = 0.5\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, stride=2),\n",
    "    torch.nn.Conv2d(6, 12, kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, stride=2),\n",
    "    torch.nn.BatchNorm2d(12), # неплохо отработал слой в плане повышения качества \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(300, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10)\n",
    ")\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "Layer Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)). X shape: torch.Size([1, 6, 28, 28])\n",
      "Layer ReLU(). X shape: torch.Size([1, 6, 28, 28])\n",
      "Layer MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False). X shape: torch.Size([1, 6, 14, 14])\n",
      "Layer Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1)). X shape: torch.Size([1, 12, 10, 10])\n",
      "Layer ReLU(). X shape: torch.Size([1, 12, 10, 10])\n",
      "Layer MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False). X shape: torch.Size([1, 12, 5, 5])\n",
      "Layer BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True). X shape: torch.Size([1, 12, 5, 5])\n",
      "Layer Flatten(). X shape: torch.Size([1, 300])\n",
      "Layer Linear(in_features=300, out_features=50, bias=True). X shape: torch.Size([1, 50])\n",
      "Layer ReLU(). X shape: torch.Size([1, 50])\n",
      "Layer Linear(in_features=50, out_features=10, bias=True). X shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 0.6027656607171322, train_acc: 0.79355, test_loss: 0.4187826104462147, test_acc: 0.8495\n",
      "ep: 1, train_loss: 0.33962345440337, train_acc: 0.8773333333333333, test_loss: 0.3453919284045696, test_acc: 0.8752\n",
      "ep: 2, train_loss: 0.29761584489903553, train_acc: 0.89155, test_loss: 0.3226435471326113, test_acc: 0.8833\n",
      "ep: 3, train_loss: 0.27376590555018565, train_acc: 0.9004333333333333, test_loss: 0.3069950744509697, test_acc: 0.8889\n",
      "ep: 4, train_loss: 0.2564999960204388, train_acc: 0.9060333333333334, test_loss: 0.2901306491345167, test_acc: 0.8933\n",
      "ep: 5, train_loss: 0.24282302957900026, train_acc: 0.9114666666666666, test_loss: 0.29185800552368163, test_acc: 0.8944\n",
      "ep: 6, train_loss: 0.23178384037728006, train_acc: 0.9157833333333333, test_loss: 0.2912297498434782, test_acc: 0.8966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-57c7a3360b38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-306badb2f464>\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(num_epochs, model)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_model(num_epochs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
